name: Scrape

on:
  schedule:
    - cron: '0 5 */3 * *' # Run every 3 days at 5am
  workflow_dispatch:
    inputs:
      logLevel:
        description: 'Log level'
        required: true
        default: 'debug'
        type: choice
        options:
          - info
          - warning
          - debug

jobs:
  scrape:
    name: Scrape Products
    runs-on: ubuntu-latest
    timeout-minutes: 90
    strategy:
      matrix:
        node-version: [18.x]
    steps:
      - uses: actions/checkout@v3

      - name: Install Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v3
        with:
          node-version: ${{ matrix.node-version }}

      - name: Install pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8
          run_install: false

      - name: Get pnpm store directory
        shell: bash
        run: echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: Setup pnpm cache
        uses: actions/cache@v3
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}

      - name: Install Node.js ${{ matrix.node-version }} modules
        run: pnpm i

      - name: Scrape products
        run: pnpm run scrape && pnpm run clean && pnpm run upload
        env:
          CLOUDFLARE_ID: ${{ secrets.CLOUDFLARE_ID }}
          ACCESS_KEY_ID: ${{ secrets.ACCESS_KEY_ID }}
          SECRET_ACCESS_KEY: ${{ secrets.SECRET_ACCESS_KEY }}

      - name: Get current date
        id: date
        run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: Upload scrape result artifact
        uses: actions/upload-artifact@v3
        with:
          name: scrape-${{ steps.date.outputs.date }}
          path: |
            webscrape/data/**/*.json
            frontend/public/**/*.json
